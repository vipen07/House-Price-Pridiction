{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Shape of train: \", train.shape)\n",
    "print(\"Shape of test: \", test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## concat train and test\n",
    "df = pd.concat((train, test))\n",
    "temp_df = df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# To show the all columns\n",
    "pd.set_option(\"display.max_columns\", 2000)\n",
    "pd.set_option(\"display.max_rows\", 85)\n",
    "df.head(6)\n",
    "\n",
    "df.tail(6)\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.describe()\n",
    " \n",
    "df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Set index as Id column\n",
    "df = df.set_index(\"Id\")\n",
    "df.head(6)\n",
    "\n",
    "# Show the null values using heatmap\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(df.isnull())\n",
    "\n",
    "\n",
    "# Get the percentages of null value\n",
    "null_percent = df.isnull().sum()/df.shape[0]*100\n",
    "null_percent\n",
    "\n",
    "\n",
    "\n",
    "col_for_drop = null_percent[null_percent > 20].keys() # if the null value % 20 or > 20 so need to drop it\n",
    "# drop columns\n",
    "df = df.drop(col_for_drop, \"columns\")\n",
    "df.shape\n",
    "(2919, 74)\n",
    "# find the unique value count\n",
    "for i in df.columns:\n",
    "    print(i + \"\\t\" + str(len(df[i].unique())))\n",
    "\n",
    "# find unique values of each column\n",
    "for i in df.columns:\n",
    "    print(\"Unique value of:>>> {} ({})\\n{}\\n\".format(i, len(df[i].unique()), df[i].unique()))\n",
    "\n",
    "\n",
    "# Describe the target \n",
    "train[\"SalePrice\"].describe()\n",
    "4\n",
    "# Plot the distplot of target\n",
    "plt.figure(figsize=(10,8))\n",
    "bar = sns.distplot(train[\"SalePrice\"])\n",
    "bar.legend([\"Skewness: {:.2f}\".format(train['SalePrice'].skew())])\n",
    "\n",
    "# correlation heatmap\n",
    "plt.figure(figsize=(25,25))\n",
    "ax = sns.heatmap(train.corr(), cmap = \"coolwarm\", annot=True, linewidth=2)\n",
    "\n",
    "# to fix the bug \"first and last row cut in half of heatmap plot\"\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "(38.0, 0.0)\n",
    "\n",
    "# correlation heatmap of higly correlated features with SalePrice\n",
    "hig_corr = train.corr()\n",
    "hig_corr_features = hig_corr.index[abs(hig_corr[\"SalePrice\"]) >= 0.5]\n",
    "hig_corr_features\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.heatmap(train[hig_corr_features].corr(), cmap = \"coolwarm\", annot=True, linewidth=3)\n",
    "# to fix the bug \"first and last row cut in half of heatmap plot\"\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "(11.0, 0.0)\n",
    "\n",
    "# Plot regplot to get the nature of highly correlated data\n",
    "plt.figure(figsize=(16,9))\n",
    "for i in range(len(hig_corr_features)):\n",
    "    if i <= 9:\n",
    "        plt.subplot(3,4,i+1)\n",
    "        plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "        sns.regplot(data=train, x = hig_corr_features[i], y = 'SalePrice')\n",
    "\n",
    "\n",
    "missing_col = df.columns[df.isnull().any()]\n",
    "missing_col\n",
    "Index(['BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFinType1',\n",
    "       'BsmtFinType2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtQual', 'BsmtUnfSF',\n",
    "       'Electrical', 'Exterior1st', 'Exterior2nd', 'Functional', 'GarageArea',\n",
    "       'GarageCars', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType',\n",
    "       'GarageYrBlt', 'KitchenQual', 'LotFrontage', 'MSZoning', 'MasVnrArea',\n",
    "       'MasVnrType', 'SaleType', 'TotalBsmtSF', 'Utilities'],\n",
    "      dtype='object')\n",
    "\n",
    "bsmt_col = ['BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFinType1',\n",
    "       'BsmtFinType2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtQual', 'BsmtUnfSF', 'TotalBsmtSF']\n",
    "bsmt_feat = df[bsmt_col]\n",
    "bsmt_feat\n",
    " \n",
    "bsmt_feat.info()\n",
    "\n",
    "bsmt_feat.isnull().sum()\n",
    "\n",
    "bsmt_feat = bsmt_feat[bsmt_feat.isnull().any(axis=1)]\n",
    "bsmt_feat\n",
    " \n",
    "\n",
    "bsmt_feat_all_nan = bsmt_feat[(bsmt_feat.isnull() | bsmt_feat.isin([0])).all(1)]\n",
    "bsmt_feat_all_nan\n",
    "\n",
    "bsmt_feat_all_nan.shape\n",
    "(79, 11)\n",
    "qual = list(df.loc[:, df.dtypes == 'object'].columns.values)\n",
    "qual\n",
    "\n",
    "# Fillinf the mising value in bsmt features\n",
    "for i in bsmt_col:\n",
    "    if i in qual:\n",
    "        bsmt_feat_all_nan[i] = bsmt_feat_all_nan[i].replace(np.nan, 'NA') # replace the NAN value by 'NA'\n",
    "    else:\n",
    "        bsmt_feat_all_nan[i] = bsmt_feat_all_nan[i].replace(np.nan, 0) # replace the NAN value inplace of 0\n",
    "\n",
    "bsmt_feat.update(bsmt_feat_all_nan) # update bsmt_feat df by bsmt_feat_all_nan\n",
    "df.update(bsmt_feat_all_nan) # update df by bsmt_feat_all_nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bsmt_feat = bsmt_feat[bsmt_feat.isin([np.nan]).any(axis=1)]\n",
    "bsmt_feat\n",
    " \n",
    "bsmt_feat.shape\n",
    "\n",
    "print(df['BsmtFinSF2'].max())\n",
    "print(df['BsmtFinSF2'].min())\n",
    "\n",
    "pd.cut(range(0,1526),5) # create a bucket\n",
    "\n",
    "df_slice = df[(df['BsmtFinSF2'] >= 305) & (df['BsmtFinSF2'] <= 610)]\n",
    "df_slice\n",
    "\n",
    "bsmt_feat.at[333,'BsmtFinType2'] = df_slice['BsmtFinType2'].mode()[0] # replace NAN value of BsmtFinType2 by mode of buet ((305.0, 610.0)\n",
    "bsmt_feat\n",
    "\n",
    " \n",
    "bsmt_feat['BsmtExposure'] = bsmt_feat['BsmtExposure'].replace(np.nan, df[df['BsmtQual'] =='Gd']['BsmtExposure'].mode()[0])\n",
    "\n",
    "df.update(bsmt_feat)\n",
    "bsmt_feat.isnull().sum()\n",
    "\n",
    "\n",
    "df.columns[df.isnull().any()]\n",
    "\n",
    "garage_col = ['GarageArea', 'GarageCars', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'GarageYrBlt',]\n",
    "garage_feat = df[garage_col]\n",
    "garage_feat = garage_feat[garage_feat.isnull().any(axis=1)]\n",
    "garage_feat\n",
    " \n",
    "garage_feat.shape\n",
    "\n",
    "garage_feat_all_nan = garage_feat[(garage_feat.isnull() | garage_feat.isin([0])).all(1)]\n",
    "garage_feat_all_nan.shape\n",
    "\n",
    "for i in garage_feat:\n",
    "    if i in qual:\n",
    "        garage_feat_all_nan[i] = garage_feat_all_nan[i].replace(np.nan, 'NA')\n",
    "    else:\n",
    "        garage_feat_all_nan[i] = garage_feat_all_nan[i].replace(np.nan, 0)\n",
    "        \n",
    "garage_feat.update(garage_feat_all_nan)\n",
    "df.update(garage_feat_all_nan)\n",
    " \n",
    "garage_feat.isnull().any()\n",
    "\n",
    "df.update(garage_feat)\n",
    "\n",
    "df.columns[df.isnull().any()]\n",
    "\n",
    "df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "df['Exterior1st'] = df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\n",
    "df['Exterior2nd'] = df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\n",
    "df['Functional'] = df['Functional'].fillna(df['Functional'].mode()[0])\n",
    "df['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\n",
    "df['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])\n",
    "df['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])\n",
    "df['Utilities'] = df['Utilities'].fillna(df['Utilities'].mode()[0])\n",
    "df['MasVnrType'] = df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df.columns[df.isnull().any()]\n",
    "\n",
    "df[df['MasVnrArea'].isnull() == True]['MasVnrType'].unique()\n",
    "#array(['None'], dtype=object)\n",
    "df.loc[(df['MasVnrType'] == 'None') & (df['MasVnrArea'].isnull() == True), 'MasVnrArea'] = 0\n",
    "df.isnull().sum()/df.shape[0] * 100\n",
    "\n",
    "\n",
    "lotconfig = ['Corner', 'Inside', 'CulDSac', 'FR2', 'FR3']\n",
    "for i in lotconfig:\n",
    "    df['LotFrontage'] = pd.np.where((df['LotFrontage'].isnull() == True) & (df['LotConfig'] == i) , df[df['LotConfig'] == i] ['LotFrontage'].mean(), df['LotFrontage'])\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "df.columns\n",
    "\n",
    "# converting columns in str which have categorical nature but in int64\n",
    "feat_dtype_convert = ['MSSubClass', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "for i in feat_dtype_convert:\n",
    "    df[i] = df[i].astype(str)\n",
    "df['MoSold'].unique() # MoSold = Month of sold# conver in month abbrevation\n",
    "import calendar\n",
    "df['MoSold'] = df['MoSold'].apply(lambda x : calendar.month_abbr[x])\n",
    "df['MoSold'].unique()\n",
    "array(['Feb', 'May', 'Sep', 'Dec', 'Oct', 'Aug', 'Nov', 'Apr', 'Jan',\n",
    "       'Jul', 'Mar', 'Jun'], dtype=object)\n",
    "quan = list(df.loc[:, df.dtypes != 'object'].columns.values)\n",
    "quan\n",
    "\n",
    "len(quan)\n",
    "\n",
    "obj_feat = list(df.loc[:, df.dtypes == 'object'].columns.values)\n",
    "obj_feat\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "df['BsmtCond'] = df['BsmtCond'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['BsmtCond'].unique()\n",
    "array([3, 4, 0, 2, 1], dtype=int64)\n",
    "df['BsmtExposure'] = df['BsmtExposure'].astype(CategoricalDtype(categories=['NA', 'Mn', 'Av', 'Gd'], ordered = True)).cat.codes\n",
    "df['BsmtExposure'].unique()\n",
    "array([-1,  3,  1,  2,  0], dtype=int64)\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].astype(CategoricalDtype(categories=['NA', 'Unf', 'LwQ', 'Rec', 'BLQ','ALQ', 'GLQ'], ordered = True)).cat.codes\n",
    "df['BsmtFinType2'] = df['BsmtFinType2'].astype(CategoricalDtype(categories=['NA', 'Unf', 'LwQ', 'Rec', 'BLQ','ALQ', 'GLQ'], ordered = True)).cat.codes\n",
    "df['BsmtQual'] = df['BsmtQual'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['ExterQual'] = df['ExterQual'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['ExterCond'] = df['ExterCond'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['Functional'] = df['Functional'].astype(CategoricalDtype(categories=['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod','Min2','Min1', 'Typ'], ordered = True)).cat.codes\n",
    "df['GarageCond'] = df['GarageCond'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['GarageQual'] = df['GarageQual'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['GarageFinish'] = df['GarageFinish'].astype(CategoricalDtype(categories=['NA', 'Unf', 'RFn', 'Fin'], ordered = True)).cat.codes\n",
    "df['HeatingQC'] = df['HeatingQC'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['KitchenQual'] = df['KitchenQual'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['PavedDrive'] = df['PavedDrive'].astype(CategoricalDtype(categories=['N', 'P', 'Y'], ordered = True)).cat.codes\n",
    "df['Utilities'] = df['Utilities'].astype(CategoricalDtype(categories=['ELO', 'NASeWa', 'NASeWr', 'AllPub'], ordered = True)).cat.codes\n",
    "df['Utilities'].unique()\n",
    "skewed_features = ['1stFlrSF',\n",
    " '2ndFlrSF',\n",
    " '3SsnPorch',\n",
    " 'BedroomAbvGr',\n",
    " 'BsmtFinSF1',\n",
    " 'BsmtFinSF2',\n",
    " 'BsmtFullBath',\n",
    " 'BsmtHalfBath',\n",
    " 'BsmtUnfSF',\n",
    " 'EnclosedPorch',\n",
    " 'Fireplaces',\n",
    " 'FullBath',\n",
    " 'GarageArea',\n",
    " 'GarageCars',\n",
    " 'GrLivArea',\n",
    " 'HalfBath',\n",
    " 'KitchenAbvGr',\n",
    " 'LotArea',\n",
    " 'LotFrontage',\n",
    " 'LowQualFinSF',\n",
    " 'MasVnrArea',\n",
    " 'MiscVal',\n",
    " 'OpenPorchSF',\n",
    " 'PoolArea',\n",
    " 'ScreenPorch',\n",
    " 'TotRmsAbvGrd',\n",
    " 'TotalBsmtSF',\n",
    " 'WoodDeckSF']\n",
    "quan == skewed_features\n",
    "False\n",
    "plt.figure(figsize=(25,20))\n",
    "for i in range(len(skewed_features)):\n",
    "    if i <= 28:\n",
    "        plt.subplot(7,4,i+1)\n",
    "        plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "        ax = sns.distplot(df[skewed_features[i]])\n",
    "        ax.legend([\"Skewness: {:.2f}\".format(df[skewed_features[i]].skew())], fontsize = 'xx-large')\n",
    "\n",
    "df_back = df\n",
    "# decrease the skewnwnes of the data\n",
    "for i in skewed_features:\n",
    "    df[i] = np.log(df[i] + 1)\n",
    "plt.figure(figsize=(25,20))\n",
    "for i in range(len(skewed_features)):\n",
    "    if i <= 28:\n",
    "        plt.subplot(7,4,i+1)\n",
    "        plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "        ax = sns.distplot(df[skewed_features[i]])\n",
    "        ax.legend([\"Skewness: {:.2f}\".format(df[skewed_features[i]].skew())], fontsize = 'xx-large')\n",
    "\n",
    "SalePrice = np.log(train['SalePrice'] + 1)\n",
    "# get object feature to conver in numeric using dummy variable\n",
    "obj_feat = list(df.loc[:,df.dtypes == 'object'].columns.values)\n",
    "len(obj_feat)\n",
    "\n",
    "# dummy varaibale\n",
    "dummy_drop = []\n",
    "clean_df = df\n",
    "for i in obj_feat:\n",
    "    dummy_drop += [i + '_' + str(df[i].unique()[-1])]\n",
    "\n",
    "df = pd.get_dummies(df, columns = obj_feat)\n",
    "df = df.drop(dummy_drop, axis = 1)\n",
    "df.shape\n",
    "\n",
    "#sns.pairplot(df)\n",
    "# scaling dataset with robust scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(df)\n",
    "df = scaler.transform(df)\n",
    "\n",
    "train_len = len(train)\n",
    "X_train = df[:train_len]\n",
    "X_test = df[train_len:]\n",
    "y_train = SalePrice\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(len(y_train))\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "def test_model(model, X_train=X_train, y_train=y_train):\n",
    "    cv = KFold(n_splits = 3, shuffle=True, random_state = 45)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    r2_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring = r2)\n",
    "    score = [r2_val_score.mean()]\n",
    "    return score\n",
    "\n",
    "import sklearn.linear_model as linear_model\n",
    "LR = linear_model.LinearRegression()\n",
    "test_model(LR)\n",
    "\n",
    "# Cross validation\n",
    "cross_validation = cross_val_score(estimator = LR, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Cross validation accuracy of LR model = \", cross_validation)\n",
    "print(\"\\nCross validation mean accuracy of LR model = \", cross_validation.mean())\n",
    "\n",
    "\n",
    "\n",
    "rdg = linear_model.Ridge()\n",
    "test_model(rdg)\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=1e-4)\n",
    "test_model(lasso)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr_reg = SVR(kernel='rbf')\n",
    "test_model(svr_reg)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_reg = DecisionTreeRegressor(random_state=21)\n",
    "test_model(dt_reg)\n",
    "r\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state=51)\n",
    "test_model(rf_reg)\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor\n",
    "br_reg = BaggingRegressor(n_estimators=1000, random_state=51)\n",
    "gbr_reg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, loss='ls', random_state=51)\n",
    "test_model(br_reg)\n",
    "\n",
    "test_model(gbr_reg)\n",
    "\n",
    "\n",
    "import xgboost\n",
    "#xgb_reg=xgboost.XGBRegressor()\n",
    "xgb_reg = xgboost.XGBRegressor(bbooster='gbtree', random_state=51)\n",
    "test_model(xgb_reg)\n",
    "\n",
    "\n",
    "svr_reg.fit(X_train,y_train)\n",
    "y_pred = np.exp(svr_reg.predict(X_test)).round(2)\n",
    "\n",
    "y_pred\n",
    "\n",
    "submit_test1 = pd.concat([test['Id'],pd.DataFrame(y_pred)], axis=1)\n",
    "submit_test1.columns=['Id', 'SalePrice']\n",
    "submit_test1\n",
    "\n",
    "\n",
    "submit_test1.to_csv('sample_submission1.csv', index=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test1.to_csv('sample_submission1.csv', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345332e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
